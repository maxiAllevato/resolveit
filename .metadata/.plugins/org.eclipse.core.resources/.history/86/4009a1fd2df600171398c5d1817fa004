package resolveit.exam_resolveit;

import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.Properties;

import edu.stanford.nlp.pipeline.StanfordCoreNLP;
import edu.stanford.nlp.semgraph.SemanticGraph;
import edu.stanford.nlp.semgraph.SemanticGraphCoreAnnotations.CollapsedCCProcessedDependenciesAnnotation;
import edu.stanford.nlp.sentiment.SentimentCoreAnnotations;
import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.trees.TreeCoreAnnotations.TreeAnnotation;
import edu.stanford.nlp.util.CoreMap;
import edu.stanford.nlp.coref.CorefCoreAnnotations.CorefChainAnnotation;
import edu.stanford.nlp.coref.data.CorefChain;
import edu.stanford.nlp.ling.CoreAnnotations.LemmaAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.NamedEntityTagAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.PartOfSpeechAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.PositionAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.SentencesAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.StemAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TextAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TokensAnnotation;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.neural.rnn.RNNCoreAnnotations;
import edu.stanford.nlp.pipeline.*;
import com.google.gson.Gson;
import com.google.gson.GsonBuilder;



/**
 * Hello world!
 *
 */
public class App 
{
    public static void main( String[] args )
    {
        System.out.println( "Init Test" );
        
        // creates a StanfordCoreNLP object, with POS tagging, lemmatization, NER, parsing, and coreference resolution
        Properties props = new Properties();
        props.setProperty("annotators", "tokenize, ssplit, pos, lemma, ner, parse, dcoref, sentiment");
        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);

        // read some text in the text variable
        String text = "For example, fish and fishes could be defined as a unique word by using their stem fish. you buy a book and then you book a room in an hotel.";
        // create an empty Annotation just with the given text
        Annotation document = new Annotation(text);

        // run all Annotators on this text
        pipeline.annotate(document);
        
     
        
     // these are all the sentences in this document
     // a CoreMap is essentially a Map that uses class objects as keys and has values with custom types
     List<CoreMap> sentences = document.get(SentencesAnnotation.class);

     for(CoreMap sentence: sentences) {
       // traversing the words in the current sentence
       // a CoreLabel is a CoreMap with additional token-specific methods
       for (CoreLabel token: sentence.get(TokensAnnotation.class)) {
         // this is the text of the token
         String word = token.get(TextAnnotation.class);
         // this is the POS tag of the token
         String pos = token.get(PartOfSpeechAnnotation.class);
         // this is the NER label of the token
         String ne = token.get(NamedEntityTagAnnotation.class);
       
         String lem = token.get(LemmaAnnotation.class);
         
         String stem = token.get(StemAnnotation.class);
         
         Tree tree = sentence.get(SentimentCoreAnnotations.SentimentAnnotatedTree.class);
         String pos2 = sentence.get(PositionAnnotation.class);
         int sent = RNNCoreAnnotations.getPredictedClass(tree);
         
       System.out.println("word " + word + " pos: " + pos + " ne :" + ne+ " lemma: " + lem + " sent : " + sent + " stem: "  + stem);

       }

       // this is the parse tree of the current sentence
       Tree tree = sentence.get(TreeAnnotation.class);

       // this is the Stanford dependency graph of the current sentence
       SemanticGraph dependencies = sentence.get(CollapsedCCProcessedDependenciesAnnotation.class);
     }

     // This is the coreference link graph
     // Each chain stores a set of mentions that link to each other,
     // along with a method for getting the most representative mention
     // Both sentence and token offsets start at 1!

     Map<Integer, CorefChain> graph = 
    		  document.get(CorefChainAnnotation.class);
        
     List<ObjectToJson> objList = new ArrayList<ObjectToJson>();
     ObjectToJson obj = new ObjectToJson();
     
     obj.setPos("NN");
     obj.setWord("Hi");
     objList.add(obj);
     
ObjectToJson obj2 = new ObjectToJson();
     
     obj2.setPos("NA");
     obj2.setWord("Good");
     
     objList.add(obj2);
     Gson gson = new Gson();

     //convert java object to JSON format
     String json = gson.toJson(objList);

     Result result = new Result();
     result.setResults(objList);
     
     Gson gson2 = new GsonBuilder().setPrettyPrinting().create();
     String json2 = gson2.toJson(result);
    
     
     System.out.println(json2);
     
        
    }
    
    
    public void selectWord() {
    	
    }
    
}
